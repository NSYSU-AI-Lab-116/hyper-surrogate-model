"""
Quick Start Guide: Dataset Comparison and Tuning

This guide shows the simplest way to use the comparison tuning functionality.
"""

import json
from pathlib import Path
from hypersurrogatemodel import TrainableLLM, ComparisonTuner
from hypersurrogatemodel.utils import Logger

# Set up logger
logger = Logger("quick_start_comparison")

def quick_start():
    """å¿«é€Ÿé–‹å§‹ï¼šæ¯”å°æ•¸æ“šé›†ä¸¦é€²è¡Œèª¿å„ª"""
    # 1. æº–å‚™æ•¸æ“šé›† (Prepare dataset)
    # æ‚¨çš„æ•¸æ“šé›†æ‡‰è©²æ˜¯JSONæ ¼å¼ï¼ŒåŒ…å«è¼¸å…¥æ–‡æœ¬å’ŒæœŸæœ›ç­”æ¡ˆ
    sample_dataset = [
        {
            "text": "é¸æ“‡é©åˆç©ºæ°£å‹•åŠ›å­¸æ¨¡æ“¬çš„ä»£ç†æ¨¡å‹ï¼Œæ•¸æ“šé»1000å€‹ï¼Œ5å€‹è¼¸å…¥è®Šé‡",
            "answer": "ç¥ç¶“ç¶²è·¯"
        },
        {
            "text": "çµæ§‹å„ªåŒ–å•é¡Œï¼Œ500å€‹æ¨£æœ¬ï¼Œ3å€‹è¨­è¨ˆè®Šé‡ï¼Œé ç®—æœ‰é™",
            "answer": "å¤šé …å¼å›æ­¸"
        },
        {
            "text": "è¤‡é›œéç·šæ€§ç³»çµ±ï¼Œ2000å€‹æ•¸æ“šé»ï¼Œ8å€‹è¼¸å…¥è®Šé‡ï¼Œéœ€è¦ä¸ç¢ºå®šæ€§é‡åŒ–",
            "answer": "é«˜æ–¯éç¨‹"
        }
    ]
    
    # ä¿å­˜æ•¸æ“šé›†
    dataset_path = "my_dataset.json"
    with open(dataset_path, 'w', encoding='utf-8') as f:
        json.dump(sample_dataset, f, indent=2, ensure_ascii=False)
    logger.success(f"æ•¸æ“šé›†å·²å‰µå»º: {dataset_path}")
    
    # 2. åˆå§‹åŒ–æ¨¡å‹ (Initialize model)
    logger.step("åˆå§‹åŒ–æ¨¡å‹...")
    model = TrainableLLM(
        base_model_name="google/gemma-3-270m-it",
        use_lora=True  # ä½¿ç”¨LoRAé€²è¡Œé«˜æ•ˆå¾®èª¿
    )
    tokenizer = model.get_tokenizer()
    
    # 3. å‰µå»ºæ¯”å°èª¿å„ªå™¨ (Create comparison tuner)
    logger.step("å‰µå»ºæ¯”å°èª¿å„ªå™¨...")
    tuner = ComparisonTuner(
        model=model,
        tokenizer=tokenizer,
        output_dir="./tuning_results",
        save_files=False  # ç¦ç”¨æª”æ¡ˆä¿å­˜ä»¥æ¸›å°‘è¼¸å‡º
    )
    
    # 4. è¼‰å…¥æ•¸æ“šé›†ä¸¦æ¯”å°å·®ç•° (Load dataset and compare differences)
    logger.info("åˆ†ææ¨¡å‹è¡¨ç¾èˆ‡æ•¸æ“šé›†ç­”æ¡ˆçš„å·®ç•°...")
    comparison_results = tuner.load_and_compare_dataset(
        dataset_path=dataset_path,
        text_column="text",      # è¼¸å…¥æ–‡æœ¬çš„æ¬„ä½å
        answer_column="answer",   # æ­£ç¢ºç­”æ¡ˆçš„æ¬„ä½å
        task_type="generation",   # ä»»å‹™é¡å‹ï¼šgeneration æˆ– classification
        comparison_method="similarity"  # æ¯”å°æ–¹æ³•ï¼šexact_match, similarity, structured
    )
    
    # 5. æŸ¥çœ‹æ¯”å°çµæœ (View comparison results)
    metrics = comparison_results['overall_metrics']
    logger.result("åˆå§‹è¡¨ç¾:")
    logger.info(f"æº–ç¢ºç‡: {metrics['accuracy']:.3f}")
    logger.info(f"å¹³å‡ç›¸ä¼¼åº¦: {metrics['average_similarity']:.3f}")
    logger.info(f"æ­£ç¢ºé æ¸¬: {metrics['correct_predictions']}")
    logger.info(f"éŒ¯èª¤é æ¸¬: {metrics['incorrect_predictions']}")
    
    # é¡¯ç¤ºéŒ¯èª¤ç¤ºä¾‹
    if comparison_results['differences']:
        logger.warning("éŒ¯èª¤ç¤ºä¾‹:")
        for i, diff in enumerate(comparison_results['differences'][:2]):
            logger.info(f"ç¤ºä¾‹ {i+1}:")
            logger.info(f"è¼¸å…¥: {diff['input_text'][:60]}...")
            logger.info(f"é æ¸¬: {diff['prediction']}")
            logger.info(f"æ­£ç¢ºç­”æ¡ˆ: {diff['ground_truth']}")
            logger.info(f"ç›¸ä¼¼åº¦: {diff['similarity']:.3f}")
    
    # 6.adaptive tuning
    if metrics['incorrect_predictions'] > 0:
        logger.step("é–‹å§‹è‡ªé©æ‡‰èª¿å„ª...")
        tuning_results = tuner.adaptive_tuning(
            comparison_results=comparison_results,
            dataset_path=dataset_path,
            text_column="text",
            answer_column="answer",
            tuning_strategy="error_focused",  
            max_epochs=2,                    # train epochs
            learning_rate=1e-5,              
        )
        
        # 7. æŸ¥çœ‹èª¿å„ªçµæœ (View tuning results)
        logger.success("èª¿å„ªå®Œæˆ!")
        pre_metrics = tuning_results['pre_tuning_metrics']
        post_metrics = tuning_results['post_tuning_metrics']
        
        logger.result(f"èª¿å„ªå‰æº–ç¢ºç‡: {pre_metrics['accuracy']:.3f}")
        logger.result(f"èª¿å„ªå¾Œæº–ç¢ºç‡: {post_metrics['accuracy']:.3f}")
        
        improvement = post_metrics['accuracy'] - pre_metrics['accuracy']
        logger.result(f"æº–ç¢ºç‡æå‡: {improvement:+.3f}")
        
        error_reduction = tuning_results['improvement_analysis']['error_reduction']
        logger.result(f"éŒ¯èª¤æ¸›å°‘: {error_reduction} å€‹æ¨£æœ¬")
        
        # 8. ä¿å­˜èª¿å„ªå¾Œçš„æ¨¡å‹ (Save tuned model)
        model_save_path = "./my_tuned_model"
        model.save_model(model_save_path)
        logger.success(f"èª¿å„ªå¾Œæ¨¡å‹å·²ä¿å­˜åˆ°: {model_save_path}")
        
    else:
        logger.success("æ¨¡å‹åœ¨æ­¤æ•¸æ“šé›†ä¸Šå·²ç¶“è¡¨ç¾å®Œç¾!")
    
    logger.info("çµæœæ–‡ä»¶ä¿å­˜åœ¨: ./tuning_results/")
    logger.success("å¿«é€Ÿé–‹å§‹å®Œæˆ!")

def test_your_own_dataset():
    """æ¸¬è©¦æ‚¨è‡ªå·±çš„æ•¸æ“šé›†"""
    
    logger.info("=" * 50)
    logger.info("ğŸ’¡ ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•¸æ“šé›†")
    logger.info("=" * 50)
    
    logger.info("""
è¦ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•¸æ“šé›†ï¼Œè«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æº–å‚™JSONæ–‡ä»¶ï¼š

{
  "data": [
    {
      "text": "æ‚¨çš„è¼¸å…¥æ–‡æœ¬",
      "answer": "æœŸæœ›çš„ç­”æ¡ˆ"
    },
    {
      "text": "å¦ä¸€å€‹è¼¸å…¥æ–‡æœ¬", 
      "answer": "å¦ä¸€å€‹æœŸæœ›ç­”æ¡ˆ"
    }
  ]
}

ç„¶å¾Œä¿®æ”¹ä»¥ä¸‹ä»£ç¢¼ä¸­çš„åƒæ•¸ï¼š

```python
# è¼‰å…¥æ‚¨çš„æ•¸æ“šé›†
comparison_results = tuner.load_and_compare_dataset(
    dataset_path="æ‚¨çš„æ•¸æ“šé›†è·¯å¾‘.json",
    text_column="text",      # æ‚¨çš„è¼¸å…¥æ–‡æœ¬æ¬„ä½å
    answer_column="answer",   # æ‚¨çš„ç­”æ¡ˆæ¬„ä½å
    task_type="generation",   # æˆ– "classification"
    comparison_method="similarity"  # æˆ– "exact_match", "structured"
)

# é€²è¡Œèª¿å„ª
tuning_results = tuner.adaptive_tuning(
    comparison_results=comparison_results,
    dataset_path="æ‚¨çš„æ•¸æ“šé›†è·¯å¾‘.json",
    text_column="text",
    answer_column="answer",
    tuning_strategy="error_focused",  # æˆ– "full_retrain", "incremental"
    max_epochs=3,
    learning_rate=2e-5,
)
```

èª¿å„ªç­–ç•¥èªªæ˜ï¼š
- error_focused: åªä½¿ç”¨éŒ¯èª¤æ¨£æœ¬é€²è¡Œè¨“ç·´ï¼ˆæ¨è–¦ï¼‰
- incremental: ä½¿ç”¨éŒ¯èª¤æ¨£æœ¬ + éƒ¨åˆ†æ­£ç¢ºæ¨£æœ¬
- full_retrain: ä½¿ç”¨å…¨éƒ¨æ•¸æ“šé‡æ–°è¨“ç·´

æ¯”å°æ–¹æ³•èªªæ˜ï¼š
- exact_match: å®Œå…¨åŒ¹é…
- similarity: åŸºæ–¼ç›¸ä¼¼åº¦æ¯”å°ï¼ˆæ¨è–¦ç”¨æ–¼æ–‡æœ¬ç”Ÿæˆï¼‰
- structured: çµæ§‹åŒ–æ¯”å°ï¼ˆç”¨æ–¼JSONç­‰æ ¼å¼åŒ–è¼¸å‡ºï¼‰
    """)

if __name__ == "__main__":
    quick_start()
