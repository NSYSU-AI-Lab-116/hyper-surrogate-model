# Dataset Comparison and Adaptive Tuning

æœ¬åŠŸèƒ½å¯¦ç¾äº†LLMè¼‰å…¥æ•¸æ“šé›†ã€ç”Ÿæˆé æ¸¬ã€èˆ‡æ­£ç¢ºç­”æ¡ˆæ¯”å°å·®ç•°ï¼Œä¸¦é€²è¡Œè‡ªé©æ‡‰èª¿å„ªçš„å®Œæ•´æµç¨‹ã€‚

## åŠŸèƒ½ç‰¹è‰²

âœ… **æ•¸æ“šé›†è¼‰å…¥èˆ‡è™•ç†**: æ”¯æ´JSONã€CSVã€JSONLæ ¼å¼  
âœ… **æ™ºèƒ½é æ¸¬ç”Ÿæˆ**: æ”¯æ´åˆ†é¡å’Œæ–‡æœ¬ç”Ÿæˆä»»å‹™  
âœ… **å¤šç¨®æ¯”å°æ–¹æ³•**: ç²¾ç¢ºåŒ¹é…ã€ç›¸ä¼¼åº¦æ¯”å°ã€çµæ§‹åŒ–æ¯”å°  
âœ… **è‡ªé©æ‡‰èª¿å„ªç­–ç•¥**: éŒ¯èª¤èšç„¦ã€å¢é‡å­¸ç¿’ã€å®Œå…¨é‡è¨“  
âœ… **è©³ç´°åˆ†æå ±å‘Š**: éŒ¯èª¤åˆ†æã€æ”¹é€²è¿½è¹¤ã€æ€§èƒ½ç›£æ§  
âœ… **LoRAé«˜æ•ˆå¾®èª¿**: åƒæ•¸æ•ˆç‡é«˜ã€è¨˜æ†¶é«”éœ€æ±‚ä½  

## ğŸ¯ å®Œæ•´å·¥ä½œæµç¨‹

```txt
1. æ•¸æ“šæº–å‚™ â†’ 2. è¼‰å…¥æ¯”å° â†’ 3. åˆ†æå·®ç•° â†’ 4. è‡ªé©æ‡‰èª¿å„ª â†’ 5. é©—è­‰æ”¹é€²
     â†“              â†“              â†“              â†“              â†“
  JSONæ ¼å¼      LLMé æ¸¬vsç­”æ¡ˆ    éŒ¯èª¤é¡å‹åˆ†æ    LoRAå¾®èª¿      æ€§èƒ½æå‡
```

## å¿«é€Ÿé–‹å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from hypersurrogatemodel import TrainableLLM, ComparisonTuner

# åˆå§‹åŒ–æ¨¡å‹å’Œèª¿å„ªå™¨
model = TrainableLLM(use_lora=True)
tuner = ComparisonTuner(model=model, tokenizer=model.get_tokenizer())

# è¼‰å…¥æ•¸æ“šé›†ä¸¦æ¯”å°å·®ç•°
results = tuner.load_and_compare_dataset(
    dataset_path="your_dataset.json",
    text_column="text",
    answer_column="answer",
    task_type="generation",
    comparison_method="similarity"
)

# åŸºæ–¼å·®ç•°é€²è¡Œè‡ªé©æ‡‰èª¿å„ª
tuning_results = tuner.adaptive_tuning(
    comparison_results=results,
    dataset_path="your_dataset.json",
    tuning_strategy="error_focused",
    max_epochs=3
)
```

### 2. æ•¸æ“šé›†æ ¼å¼

æ‚¨çš„æ•¸æ“šé›†æ‡‰è©²æ˜¯JSONæ ¼å¼ï¼š

```json
[
  {
    "text": "è¼¸å…¥æ–‡æœ¬ï¼šé¸æ“‡é©åˆçš„ä»£ç†æ¨¡å‹",
    "answer": "ç¥ç¶“ç¶²è·¯"
  },
  {
    "text": "å¦ä¸€å€‹è¼¸å…¥æ–‡æœ¬",
    "answer": "æœŸæœ›çš„ç­”æ¡ˆ"
  }
]
```

## è©³ç´°åŠŸèƒ½èªªæ˜

### æ¯”å°æ–¹æ³• (Comparison Methods)

1. **exact_match**: å®Œå…¨åŒ¹é…
   - é©ç”¨æ–¼åˆ†é¡ä»»å‹™
   - é æ¸¬å€¼å¿…é ˆèˆ‡æ­£ç¢ºç­”æ¡ˆå®Œå…¨ç›¸åŒ

2. **similarity**: ç›¸ä¼¼åº¦æ¯”å°  
   - é©ç”¨æ–¼æ–‡æœ¬ç”Ÿæˆä»»å‹™
   - åŸºæ–¼tokené‡ç–Šè¨ˆç®—ç›¸ä¼¼åº¦
   - æ¨è–¦é–¾å€¼ï¼š0.8

3. **structured**: çµæ§‹åŒ–æ¯”å°
   - é©ç”¨æ–¼JSONç­‰æ ¼å¼åŒ–è¼¸å‡º
   - æ”¯æ´éƒ¨åˆ†åŒ¹é…è©•åˆ†

### èª¿å„ªç­–ç•¥ (Tuning Strategies)

1. **error_focused**: éŒ¯èª¤èšç„¦ï¼ˆæ¨è–¦ï¼‰
   - åƒ…ä½¿ç”¨éŒ¯èª¤é æ¸¬çš„æ¨£æœ¬é€²è¡Œè¨“ç·´
   - é«˜æ•ˆä¸”é‡å°æ€§å¼·
   - é©åˆéŒ¯èª¤ç‡è¼ƒä½çš„æƒ…æ³

2. **incremental**: å¢é‡å­¸ç¿’
   - ä½¿ç”¨éŒ¯èª¤æ¨£æœ¬ + éƒ¨åˆ†æ­£ç¢ºæ¨£æœ¬
   - å¹³è¡¡æ”¹é€²èˆ‡ç©©å®šæ€§
   - é©åˆä¸­ç­‰éŒ¯èª¤ç‡çš„æƒ…æ³

3. **full_retrain**: å®Œå…¨é‡è¨“
   - ä½¿ç”¨å…¨éƒ¨æ•¸æ“šé‡æ–°è¨“ç·´
   - æœ€å…¨é¢ä½†è€—æ™‚è¼ƒé•·
   - é©åˆéŒ¯èª¤ç‡å¾ˆé«˜çš„æƒ…æ³

### ä»»å‹™é¡å‹ (Task Types)

1. **classification**: åˆ†é¡ä»»å‹™
   - è¼¸å‡ºå›ºå®šé¡åˆ¥
   - ä½¿ç”¨åˆ†é¡æå¤±å‡½æ•¸
   - è©•ä¼°æŒ‡æ¨™ï¼šæº–ç¢ºç‡ã€F1åˆ†æ•¸

2. **generation**: æ–‡æœ¬ç”Ÿæˆä»»å‹™
   - è‡ªç”±æ–‡æœ¬è¼¸å‡º
   - ä½¿ç”¨èªè¨€æ¨¡å‹æå¤±å‡½æ•¸  
   - è©•ä¼°æŒ‡æ¨™ï¼šç›¸ä¼¼åº¦ã€å›°æƒ‘åº¦

## å®Œæ•´ç¤ºä¾‹

### ä»£ç†æ¨¡å‹é¸æ“‡ç¤ºä¾‹

```python
import json
from hypersurrogatemodel import TrainableLLM, ComparisonTuner

# å‰µå»ºä»£ç†æ¨¡å‹é¸æ“‡æ•¸æ“šé›†
dataset = [
    {
        "text": "è¨­è¨ˆç©ºæ°£å‹•åŠ›å­¸æ¨¡æ“¬çš„ä»£ç†æ¨¡å‹ï¼Œ1000å€‹æ•¸æ“šé»ï¼Œ5å€‹è¼¸å…¥è®Šé‡ï¼Œéœ€è¦é«˜ç²¾åº¦",
        "answer": "ç¥ç¶“ç¶²è·¯"
    },
    {
        "text": "çµæ§‹å„ªåŒ–å•é¡Œï¼Œ500å€‹æ¨£æœ¬ï¼Œ3å€‹è¨­è¨ˆè®Šé‡ï¼Œé ç®—æœ‰é™", 
        "answer": "å¤šé …å¼å›æ­¸"
    },
    {
        "text": "è¤‡é›œéç·šæ€§ç³»çµ±ï¼Œ2000å€‹æ•¸æ“šé»ï¼Œ8å€‹è¼¸å…¥è®Šé‡ï¼Œéœ€è¦ä¸ç¢ºå®šæ€§é‡åŒ–",
        "answer": "é«˜æ–¯éç¨‹"
    }
]

# ä¿å­˜æ•¸æ“šé›†
with open("surrogate_dataset.json", "w", encoding="utf-8") as f:
    json.dump(dataset, f, indent=2, ensure_ascii=False)

# åˆå§‹åŒ–æ¨¡å‹
model = TrainableLLM(
    base_model_name="google/gemma-3-270m-it",
    use_lora=True,
    lora_config={
        "r": 8,
        "lora_alpha": 16,
        "lora_dropout": 0.1,
        "target_modules": ["q_proj", "v_proj"]
    }
)

# å‰µå»ºèª¿å„ªå™¨
tuner = ComparisonTuner(
    model=model,
    tokenizer=model.get_tokenizer(),
    output_dir="./results"
)

# è¼‰å…¥ä¸¦æ¯”å°
print("åˆ†æåˆå§‹æ€§èƒ½...")
results = tuner.load_and_compare_dataset(
    dataset_path="surrogate_dataset.json",
    text_column="text",
    answer_column="answer", 
    task_type="generation",
    comparison_method="similarity"
)

print(f"æº–ç¢ºç‡: {results['overall_metrics']['accuracy']:.3f}")
print(f"éŒ¯èª¤æ•¸é‡: {results['overall_metrics']['incorrect_predictions']}")

# è‡ªé©æ‡‰èª¿å„ª
if results['overall_metrics']['incorrect_predictions'] > 0:
    print("\\né–‹å§‹è‡ªé©æ‡‰èª¿å„ª...")
    tuning_results = tuner.adaptive_tuning(
        comparison_results=results,
        dataset_path="surrogate_dataset.json",
        text_column="text",
        answer_column="answer",
        tuning_strategy="error_focused",
        max_epochs=3,
        learning_rate=1e-5
    )
    
    # é¡¯ç¤ºæ”¹é€²
    improvement = tuning_results['improvement_analysis']
    print(f"æº–ç¢ºç‡æ”¹é€²: {improvement['improvements']['accuracy']['absolute_improvement']:+.3f}")
    print(f"éŒ¯èª¤æ¸›å°‘: {improvement['error_reduction']} å€‹æ¨£æœ¬")

# ä¿å­˜èª¿å„ªå¾Œçš„æ¨¡å‹
model.save_model("./tuned_surrogate_model")
print("èª¿å„ªå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜ã€‚")
```

## è¼¸å‡ºçµæœ

### æ¯”å°çµæœç¤ºä¾‹

```json
{
  "overall_metrics": {
    "accuracy": 0.750,
    "average_similarity": 0.823,
    "total_samples": 8,
    "correct_predictions": 6,
    "incorrect_predictions": 2
  },
  "error_analysis": {
    "error_types": {
      "partial_match": 1,
      "completely_different": 1
    },
    "most_common_error": "partial_match"
  },
  "differences": [
    {
      "index": 2,
      "input_text": "è¤‡é›œéç·šæ€§ç³»çµ±...",
      "prediction": "æ”¯æ´å‘é‡æ©Ÿ",
      "ground_truth": "é«˜æ–¯éç¨‹", 
      "similarity": 0.456,
      "difference_type": "completely_different"
    }
  ]
}
```

### èª¿å„ªçµæœç¤ºä¾‹

```json
{
  "tuning_strategy": "error_focused",
  "pre_tuning_metrics": {
    "accuracy": 0.750,
    "incorrect_predictions": 2
  },
  "post_tuning_metrics": {
    "accuracy": 0.875,
    "incorrect_predictions": 1
  },
  "improvement_analysis": {
    "improvements": {
      "accuracy": {
        "absolute_improvement": 0.125,
        "percentage_improvement": 16.7
      }
    },
    "error_reduction": 1
  }
}
```

## é€²éšé…ç½®

### è‡ªå®šç¾©LoRAé…ç½®

```python
model = TrainableLLM(
    use_lora=True,
    lora_config={
        "r": 16,                    # LoRA rank
        "lora_alpha": 32,           # LoRA scaling parameter  
        "lora_dropout": 0.1,        # Dropout rate
        "target_modules": [         # Target modules for LoRA
            "q_proj", "v_proj", 
            "k_proj", "o_proj"
        ],
    }
)
```

### è‡ªå®šç¾©è¨“ç·´åƒæ•¸

```python
tuning_results = tuner.adaptive_tuning(
    comparison_results=results,
    dataset_path="dataset.json",
    tuning_strategy="incremental",
    max_epochs=5,
    learning_rate=2e-5,
)
```

### ä½¿ç”¨Weights & Biasesè¿½è¹¤

```python
tuner = ComparisonTuner(
    model=model,
    tokenizer=tokenizer,
    output_dir="./results",
    use_wandb=True  # å•Ÿç”¨W&Bè¿½è¹¤
)
```

## å¸¸è¦‹å•é¡Œ

### Q: å¦‚ä½•è™•ç†å¤§å‹æ•¸æ“šé›†ï¼Ÿ

A: ç³»çµ±è‡ªå‹•æŒ‰æ‰¹æ¬¡è™•ç†ï¼Œå¯ä»¥èª¿æ•´ `batch_size` åƒæ•¸ä¾†æ§åˆ¶è¨˜æ†¶é«”ä½¿ç”¨ã€‚

### Q: èª¿å„ªéœ€è¦å¤šé•·æ™‚é–“ï¼Ÿ

A: å–æ±ºæ–¼æ•¸æ“šé›†å¤§å°å’Œæ¨¡å‹è¤‡é›œåº¦ã€‚error_focusedç­–ç•¥é€šå¸¸æœ€å¿«ï¼Œå› ç‚ºåªè¨“ç·´éŒ¯èª¤æ¨£æœ¬ã€‚

### Q: å¦‚ä½•é¸æ“‡æ¯”å°æ–¹æ³•ï¼Ÿ

A:

- åˆ†é¡ä»»å‹™ä½¿ç”¨ `exact_match`
- æ–‡æœ¬ç”Ÿæˆä½¿ç”¨ `similarity`
- JSONè¼¸å‡ºä½¿ç”¨ `structured`

### Q: ç‚ºä»€éº¼åˆå§‹æº–ç¢ºç‡æ˜¯0.0%ï¼Ÿé€™æ­£å¸¸å—ï¼Ÿ

A:

**å®Œå…¨æ­£å¸¸ï¼** é€™å¯¦éš›ä¸Šè­‰æ˜äº†èª¿å„ªçš„å¿…è¦æ€§å’Œåƒ¹å€¼ï¼š

1. **é€šç”¨LLMçš„å±€é™æ€§**ï¼š
   - åœ¨é€šç”¨æ–‡æœ¬ä¸Šè¨“ç·´ï¼Œç¼ºä¹å°ˆæ¥­å·¥ç¨‹çŸ¥è­˜
   - ä¸äº†è§£ä»£ç†æ¨¡å‹é¸æ“‡çš„å°ˆæ¥­è¡“èªå’Œé‚è¼¯
   - è¼¸å‡ºæ ¼å¼å¯èƒ½ä¸ç¬¦åˆé æœŸ

2. **å°ˆæ¥­ä»»å‹™çš„æŒ‘æˆ°**ï¼š
   - éœ€è¦æ·±åº¦çš„å·¥ç¨‹å’Œæ•¸å€¼æ–¹æ³•çŸ¥è­˜
   - è¦ç†è§£ä¸åŒç®—æ³•çš„é©ç”¨å ´æ™¯
   - éœ€è¦çµ¦å‡ºç²¾ç¢ºçš„æŠ€è¡“è¡“èª

3. **é€™æ­£æ˜¯èª¿å„ªçš„åƒ¹å€¼**ï¼š
   - å°‡é€šç”¨æ™ºèƒ½è½‰åŒ–ç‚ºå°ˆæ¥­æ™ºèƒ½
   - å¾"çŸ¥é“å¾ˆå¤š"åˆ°"å°ˆç²¾ä¸€åŸŸ"
   - 0% â†’ 60-90% çš„æ”¹é€²ç©ºé–“å·¨å¤§

**æœŸæœ›æ”¹é€²è·¯å¾‘**ï¼šåˆå§‹0% â†’ ç¬¬1è¼ª40% â†’ ç¬¬2è¼ª70% â†’ ç¬¬3è¼ª85%

## æ–‡ä»¶çµæ§‹

èª¿å„ªå®Œæˆå¾Œæœƒç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```text
./comparison_tuning_results/
â”œâ”€â”€ comparison_results_20240101_120000.json    # æ¯”å°çµæœ
â”œâ”€â”€ tuning_results_20240101_120000.json        # èª¿å„ªçµæœ  
â”œâ”€â”€ adaptive_tuning/                           # è¨“ç·´è¼¸å‡º
â”‚   â”œâ”€â”€ checkpoint-100/                        # æ¨¡å‹æª¢æŸ¥é»
â”‚   â””â”€â”€ logs/                                  # è¨“ç·´æ—¥èªŒ
â””â”€â”€ performance_logs/                          # æ€§èƒ½è¿½è¹¤
    â””â”€â”€ performance_log_20240101.json
```

## ç›¸é—œæ–‡ä»¶

- `examples/comparison_tuning_example.py` - å®Œæ•´ç¤ºä¾‹
- `examples/quick_start_comparison.py` - å¿«é€Ÿé–‹å§‹æŒ‡å—
- `hypersurrogatemodel/comparison_tuner.py` - æ ¸å¿ƒå¯¦ç¾

---

æœ‰ä»»ä½•å•é¡Œæ­¡è¿æŸ¥çœ‹ç¤ºä¾‹ä»£ç¢¼æˆ–æå‡ºissueï¼
